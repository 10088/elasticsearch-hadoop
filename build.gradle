buildscript {
    repositories {
        maven { url 'http://repo.springsource.org/plugins-release' }
    }
    dependencies {
        classpath 'org.springframework.build.gradle:propdeps-plugin:0.0.3'
    }
}

repositories {
  mavenCentral()
  maven { url "http://oss.sonatype.org/content/groups/public/" }
  // JDO ec2 missing from Maven Central
  maven { url "http://www.datanucleus.org/downloads/maven2" }
  maven { url "http://conjars.org/repo" }
}

apply plugin: "java"
apply plugin: 'eclipse'
apply plugin: 'idea'
apply from: "$rootDir/maven.gradle"
apply plugin: 'propdeps'
apply plugin: 'propdeps-idea'
apply plugin: 'propdeps-eclipse'

def List hadoop = []
def hadoopDistro = project.hasProperty("distro") ? project.getProperty("distro") : "hadoopStable"

// Hadoop aliases
def hadoopStableVersion = hadoop11Version
def hadoopYarnVersion = hadoop2Version
def hadoopVersion = hadoopStableVersion 

switch (hadoopDistro) {

  // Hadoop YARN/2.0.x
  case "hadoopYarn":
    hadoopVersion = hadoopYarnVersion
    println "Using Apache Hadoop YARN [$hadoopVersion]"
    hadoop = ["org.apache.hadoop:hadoop-client:$hadoopVersion"]

    break;
  // Hadoop 1.2.x
  case "hadoop12":
    hadoopVersion = hadoop12Version
    println "Using Apache Hadoop 1.2.x [$hadoopVersion]"
    hadoop = ["org.apache.hadoop:hadoop-streaming:$hadoopVersion",
              "org.apache.hadoop:hadoop-tools:$hadoopVersion"]

    break;
	
  // Hadoop 1.1.x
  case "hadoop11":
    hadoopVersion = hadoop11Version
    println "Using Apache Hadoop 1.1.x [$hadoopVersion]"
    hadoop = ["org.apache.hadoop:hadoop-streaming:$hadoopVersion",
              "org.apache.hadoop:hadoop-tools:$hadoopVersion"]

    break;

  // Hadoop 1.0.x
  case "hadoop10":
    hadoopVersion = hadoop10Version
    println "Using Apache Hadoop 1.0.x [$hadoopVersion]"
    hadoop = ["org.apache.hadoop:hadoop-streaming:$hadoopVersion",
              "org.apache.hadoop:hadoop-tools:$hadoopVersion"]

    break;

  default:
    println "Using Apache Hadoop Stable [$hadoopVersion]"
    hadoopVersion = hadoopStableVersion
    hadoop = ["org.apache.hadoop:hadoop-streaming:$hadoopVersion",
              "org.apache.hadoop:hadoop-tools:$hadoopVersion"] 
}

dependencies {
	compile hadoop
	
	compile("org.codehaus.jackson:jackson-mapper-asl:$jacksonVersion")
    testRuntime("log4j:log4j:$log4jVersion")

    // Pig
    optional("org.apache.pig:pig:$pigVersion")

	ext.hiveGroup = "org.apache.hive"
    // Hive
    optional("$hiveGroup:hive-service:$hiveVersion")
	
	// Cascading
	optional("cascading:cascading-hadoop:$cascadingVersion")
	optional("cascading:cascading-local:$cascadingVersion")
    
    // needed by the Hive Server tests - removed since Hive 0.11
    // testRuntime "$hiveGroup:hive-builtins:$hiveVersion"

    // Testing
    testCompile "junit:junit:$junitVersion"
	testCompile "org.hamcrest:hamcrest-all:$hamcrestVersion"
    testCompile "org.elasticsearch:elasticsearch:$esVersion"
	
	if (hadoopVersion.contains("1.0.")) {
		// missing dependency in Hadoop 1.0.3/1.0.4
		testCompile "commons-io:commons-io:2.1"
	}
	
	// Required by Pig
	testRuntime "com.google.guava:guava:11.0"
	testRuntime "dk.brics.automaton:automaton:1.11-8"
	testRuntime "joda-time:joda-time:$jodaVersion"
	
	// Required by Hive + Pig
	// testRuntime "org.antlr:antlr-runtime:$antlrVersion"
	
	// Required by Hive
	testRuntime "org.apache.hive:hive-jdbc:$hiveVersion"
}

configurations.all {
  resolutionStrategy {
	forcedModules = ['commons-httpclient:commons-httpclient:3.0.1']
  }
}

sourceCompatibility = 1.6
targetCompatibility = 1.6 

ext.skipCascading = true
ext.skipMR = true
ext.skipHive = true
ext.skipPig = true

task enableMRTests {
    description = "Enable Map/Reduce tests"
    group = "Verification"
    doLast() {
        project.ext.skipMR = false
   }
}

task enableCascadingTests {
    description = "Enable Cascading tests"
    group = "Verification"
    doLast() {
        project.ext.skipCascading = false
   }
}

task enableHiveTests {
    description = "Enable Hive tests"
    group = "Verification"
    doLast() {
        project.ext.skipHive = false
  }
}

task enablePigTests {
    description = "Enable Pig tests"
    group = "Verification"
    
    doLast() {
        project.ext.skipPig = false
  }
}

task enableIntegrationTests() {
    description = "Enable integration tests"
    group = "Verification"
    doLast() {
      println "Enable all integration tests"
	  enableMRTests.execute()
  	  enableCascadingTests.execute()
	  enablePigTests.execute()
	  //enableHiveTests.execute()
    }
}

test {
    systemProperties['input.path'] = 'build/classes/test/input'
    systemProperties['output.path'] = 'build/classes/test/output'
    includes = ["org/elasticsearch/hadoop/serialization/*.class", 
				"org/elasticsearch/hadoop/pig/*.class",
				"org/elasticsearch/hadoop/rest/*.class",
				"org/elasticsearch/hadoop/util/**/*.class", 
				"org/elasticsearch/hadoop/integration/**/*Suite.class"]

	minHeapSize = "256m"
	maxHeapSize = "512m"

    testLogging {
        events "started" //, "standardOut", "standardError"
        minGranularity 2
        maxGranularity 2
    }
	
    doFirst() {
        ext.msg = ""

        if (skipMR) {
            ext.msg += "MapReduce "
            excludes.add("**/integration/mr/**")
        }
        if (skipCascading) {
            ext.msg += "Cascading "
            excludes.add("**/integration/cascading/**")
        }
        if (skipHive) {
            ext.msg += "Hive "
            excludes.add("**/integration/hive/**")
        }
        if (skipPig) {
            ext.msg += "Pig"
            excludes.add("**/integration/pig/**")
        }

        if (!msg.isEmpty())
            println "Skipping [$msg] Tests";
	}
}

task sourcesJar(type: Jar, dependsOn:classes) {
    classifier = 'sources'
    from sourceSets.main.allJava
}

task javadocJar(type: Jar) {
    classifier = 'javadoc'
    from javadoc
}

// jar used for testing Hadoop remotely (es-hadoop + tests)
task hadoopTestingJar(type: Jar) {
	classifier = 'testing'
	from sourceSets.test.output
	from sourceSets.main.output
}

jar {
    manifest.attributes["Created-By"] = "${System.getProperty("java.version")} (${System.getProperty("java.specification.vendor")})"
    manifest.attributes['Implementation-Title'] = 'elasticsearch-hadoop'
    manifest.attributes['Implementation-Version'] = project.version
    manifest.attributes['Implementation-URL'] = "http://github.com/elasticsearch/elasticsearch-hadoop"
    manifest.attributes['Implementation-Vendor'] = "Elasticsearch"
    manifest.attributes['Implementation-Vendor-Id'] = "org.elasticsearch.hadoop"
    
    def build = System.env['ESHDP.BUILD']
    if (build != null)
        manifest.attributes['Build'] = build
    
    String rev = "unknown"
    
    // parse the git files to find out the revision
    File gitHead = file('.git/HEAD')
    if (gitHead.exists()) {
        gitHead = file('.git/' + gitHead.text.trim().replace('ref: ',''))
        if (gitHead.exists()) { rev = gitHead.text }
    }

    from("$rootDir/docs/src/info") {
        include "license.txt"
        include "notice.txt"
        into "META-INF"
        expand(copyright: new Date().format('yyyy'), version: project.version)
    }

    manifest.attributes['Repository-Revision'] = rev
}

artifacts {
    archives sourcesJar
    archives javadocJar
}

task wrapper(type: Wrapper) {
    description = 'Generates gradlew[.bat] scripts'
    gradleVersion = '1.4'
}

// skip creation of javadoc jars 
assemble.dependsOn = ['jar', 'hadoopTestingJar']
defaultTasks 'build'